{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SPM batch script generator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Following scripts are available\n",
    "#### 1. Import DICOMs\n",
    "#### 2. Realign & Slice timing\n",
    "#### 3. Coregister & Segment & Normalize & Smoothing\n",
    "#### 4. fMRI model specification\n",
    "#### 5. Contrast Manager"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tkinter as TK\r\n",
    "import os, shutil\r\n",
    "import pandas as pd\r\n",
    "from glob import glob\r\n",
    "from tkinter import filedialog, messagebox\r\n",
    "from tqdm.notebook import tqdm\r\n",
    "import nibabel as nib\r\n",
    "\r\n",
    "TEMP = TK.Tk(); _ = TEMP.withdraw()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_script(path, fname, info = \"%% SPM DICOM Import Batch Maker by Kim Yun Heung\\n\"):\r\n",
    "    File = open(path + '/' + fname,'w')\r\n",
    "    File.write(info)\r\n",
    "\r\n",
    "    runner = open(path + '/run' + fname.split('.')[0] + '.m', 'w')\r\n",
    "    runner.write(\"\"\"%% List of open inputs\r\n",
    "nrun = 1; %% enter the number of runs here\r\n",
    "jobfile = {'%s'};\r\n",
    "jobs = repmat(jobfile, 1, nrun);\r\n",
    "inputs = cell(0, nrun);\r\n",
    "for crun = 1:nrun\r\n",
    "end\r\n",
    "spm('defaults', 'FMRI');\r\n",
    "spm_jobman('run', jobs, inputs{:});\r\n",
    "\"\"\"%(path + '/' + fname))\r\n",
    "    return File\r\n",
    "\r\n",
    "def Ask_directory(Title='Test'):\r\n",
    "    Path =  filedialog.askdirectory(title=Title,initialdir=os.getcwd())\r\n",
    "    os.chdir(Path)\r\n",
    "    return Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Main Presets`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Sequence = { 'Anatomy': 'BRAVO'   ,\r\n",
    "             'fMRI'   : 'NEGATIVE' }\r\n",
    "Folder_Structure = '/*/*/' # Subject / sequence\r\n",
    "SPM_PATH = 'C:/Users/KIM/Documents/MATLAB/spm12/'\r\n",
    "base_dir = os.getcwd()\r\n",
    "\r\n",
    "script_path = Ask_directory('Where to save script files?')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(script_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #1 Import DICOMs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Presets`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def script1_writer(index, path, destination , File):\r\n",
    "    File.write('matlabbatch{%d}.spm.util.import.dicom.data = {\\n'%(index))\r\n",
    "    for dcm in sorted(glob(path + '/*')): \r\n",
    "        File.write(\"\t'\" + dcm + \"'\\n\")\r\n",
    "    File.write('};')\r\n",
    "    File.write(\"\"\"\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.root = 'flat';\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.outdir = {'%s'};\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.protfilter = '.*';\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.convopts.format = 'nii';\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.convopts.meta = 0;\r\n",
    "matlabbatch{%d}.spm.util.import.dicom.convopts.icedims = 0;\\n\\n\"\"\"%(index, index, destination, index, index, index, index))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dicom_path = Ask_directory('Where are the DICOM files?')\r\n",
    "nifti_path = Ask_directory('Where to save NiFTI files?')\r\n",
    "try: os.mkdir(nifti_path + '/NIFTI')\r\n",
    "except: print('Warning: The folder is already exist! Your data will be overwritten!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(dicom_path)\r\n",
    "print(nifti_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Anatomy_list, Anatomy_nifti = pd.DataFrame(), pd.DataFrame()\r\n",
    "Anatomy_list['Path'], Anatomy_nifti['Path'] = None, None\r\n",
    "fMRI_list, fMRI_nifti = pd.DataFrame(), pd.DataFrame()\r\n",
    "fMRI_list['Path'], fMRI_nifti['Path'] = None, None\r\n",
    "index = 0\r\n",
    "\r\n",
    "for subject in glob(dicom_path + '/*'):\r\n",
    "    input_conditions = [False, False]\r\n",
    "    if os.path.isdir(subject):\r\n",
    "        Subject = subject.split('\\\\')[-1]\r\n",
    "        for sequence in glob(subject+'/*'):\r\n",
    "            if   Sequence['Anatomy'] in sequence.upper(): input_conditions[0] = sequence#; print(subject)\r\n",
    "            elif Sequence['fMRI'] in sequence.upper()   : input_conditions[1] = sequence#; print(subject)\r\n",
    "            else: pass\r\n",
    "        if False not in input_conditions:\r\n",
    "            try: os.mkdir(nifti_path + '/NIFTI/' + Subject)\r\n",
    "            except: pass\r\n",
    "            for seq in [Sequence['Anatomy'], Sequence['fMRI']]:\r\n",
    "                try: os.mkdir(nifti_path + '/NIFTI/' + Subject + '/' + seq)\r\n",
    "                except: pass\r\n",
    "            Anatomy_list.loc[index] = input_conditions[0]\r\n",
    "            Anatomy_nifti.loc[index] = nifti_path + '/NIFTI/' + Subject + '/' + Sequence['Anatomy']\r\n",
    "            fMRI_list.loc[index] = input_conditions[1]\r\n",
    "            fMRI_nifti.loc[index] = nifti_path + '/NIFTI/' + Subject + '/' + Sequence['fMRI'] \r\n",
    "            index += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Anatomy total:',len(Anatomy_nifti))\r\n",
    "print('fMRI total:'   ,len(fMRI_nifti)  )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script1 = create_script(script_path, 'script1.m')\r\n",
    "print('Writing script...', end=' ')\r\n",
    "\r\n",
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(Anatomy_list['Path'])*2,2)):\r\n",
    "    script1_writer(i+1, Anatomy_list['Path'].loc[idx], Anatomy_nifti['Path'][idx], File=script1)\r\n",
    "    script1_writer(i+2, fMRI_list['Path'].loc[idx], fMRI_nifti['Path'][idx], File=script1)\r\n",
    "    idx += 1\r\n",
    "    \r\n",
    "print('Done!'); script1.close()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #2 Realign & Slice timing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Script #2 presets`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "realign = {\r\n",
    "    ##Estimation Options##\r\n",
    "    'Quality'      : 0.9,       #0~1, higher the better, lower the faster\r\n",
    "    'Separation'   : 4,         #The separation (in mm) between the points sampled in the reference image\r\n",
    "    'Smoothing'    : 5,         #The FWHM of the Gaussian smoothing kernel (mm) applied to the images before estimating\r\n",
    "    'Num_Passes'   : 1,         #0: Register to first, 1: Register to mean\r\n",
    "    'Interpolation': 2,         #0: Trilinear, 2~7: n-th Degree B-Spline\r\n",
    "    'Wrap'         : '[0 0 0]', #[X, Y, Z], 0: no wrapping, 1: wrapping for the P.E direction\r\n",
    "    ##Reslice Options##\r\n",
    "    'Masking'      : 1,       #Searching through the whole time series looking for voxels which need to be \r\n",
    "                              #sampled from outside the original images.\r\n",
    "    'fname_prefix' : 'r'      #default: 'r'\r\n",
    "}\r\n",
    "\r\n",
    "sliceTiming = {\r\n",
    "    'Number of slices': 'AUTO',  #Number of slices will be filled automatically.\r\n",
    "    'TR'              : 3     ,  #n * 1000ms\r\n",
    "    'TA'              : 'AUTO',  #TA will be filled automatically.\r\n",
    "    'Slice_order'     : 'AUTO',  #slice order will be filled automatically\r\n",
    "    'Reference slice' : 1     ,  #If slice times are provided instead of slice indices in the previous item, this value should\r\n",
    "                                 #represent a reference time (in ms) instead of the slice index of the reference slice.\r\n",
    "    'fname_prefix' : 'a'         #default: 'a'\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def script2_writer(index, path, realign, sliceT, File):\r\n",
    "    LIST = sorted(glob(path + '/s*.nii'))\r\n",
    "    print(path + '/*')\r\n",
    "    reference = nib.load(LIST[0]).get_fdata()\r\n",
    "    nslices   = reference.shape[-1]\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.data = {\\n\"%(index))\r\n",
    "    File.write('                                                    {\\n')\r\n",
    "    for nif in LIST: File.write(\"                                                    '\" + nif + \"'\\n\")\r\n",
    "    TA = sliceT['TR'] - sliceT['TR']/nslices\r\n",
    "    slice_order = str([i for i in range(1, nslices if nslices%2==0 else nslices+1 ,2)] + [i for i in range(2, nslices+1 if nslices%2==0 else nslices, 2)]).replace(',','')\r\n",
    "    File.write('                                                    }\\n')\r\n",
    "    File.write(\"                                                    }';\\n\")\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.quality = %s;\\n\"%(  index, realign['Quality']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.sep = %s;\\n\"%(      index, realign['Separation']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.fwhm = %s;\\n\"%(     index, realign['Smoothing']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.rtm = %s;\\n\"%(      index, realign['Num_Passes']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.interp = %s;\\n\"%(   index, realign['Interpolation']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.wrap = %s;\\n\"%(     index, realign['Wrap']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.eoptions.weight = '';\\n\"%(   index  ))\r\n",
    "\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.roptions.which = [2 1];\\n\"%( index  )) #[All images, Mean image]\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.roptions.interp = 4;\\n\"%(    index  ))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.roptions.wrap = %s;\\n\"%(     index, realign['Wrap']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.roptions.mask = %s;\\n\"%(     index, realign['Masking']))\r\n",
    "    #File.write(\"matlabbatch{%d}.spm.spatial.realign.estwrite.roptions.prefix = '%s';\\n\"%( index, realign['fname_prefix']))\r\n",
    "\r\n",
    "    File.write(\r\n",
    "\"\"\"matlabbatch{%d}.spm.temporal.st.scans{1}(1) = cfg_dep('Realign: Estimate & Reslice: Resliced Images (Sess 1)', substruct('.','val', '{}',{%d}, '.','val', '{}',{1}, '.','val', '{}',{1}, '.','val', '{}',{1}), substruct('.','sess', '()',{1}, '.','rfiles'));\\n\"\"\"%(index+1,index))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.nslices = %s;\\n\"%( index+1, nslices))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.tr = %d;\\n\"%(      index+1, sliceT['TR']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.ta = %s;\\n\"%(      index+1, TA))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.so = %s\\n\"%(       index+1, slice_order))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.refslice = %s;\\n\"%(index+1, sliceTiming['Reference slice']))\r\n",
    "    File.write(\"matlabbatch{%d}.spm.temporal.st.prefix = '%s';\\n\"%(index+1, sliceTiming['fname_prefix']))\r\n",
    "    File.write(\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script2 = create_script(script_path, 'script2.m', info=\"%% SPM Realign & Slice Timing Batch Maker by Kim Yun Heung\\n\")\r\n",
    "print('Writing script...')\r\n",
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(fMRI_list['Path'])*2,2)):\r\n",
    "    #print(fMRI_nifti['Path'][idx])\r\n",
    "    script2_writer(i+1, fMRI_nifti['Path'][idx], realign, sliceTiming, File=script2)\r\n",
    "    idx += 1\r\n",
    "#break\r\n",
    "script2.close()\r\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #3 Coregister & Segment & Normalize & Smoothing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "auto_backup = messagebox.askyesno('Auto backup',\"When you are doing coregister sequence, all of the T1 images will be overwritten with coregistered T1 images. Click 'yes' to backup all of the T1 images before continue.\")\r\n",
    "\r\n",
    "if auto_backup:\r\n",
    "    directory = filedialog.askdirectory(title='Where to save?',initialdir=os.getcwd())\r\n",
    "    try: os.mkdir(directory+'/T1_backup')\r\n",
    "    except: print('Warning: The folder is already exist! Your data will be overwritten!')\r\n",
    "    \r\n",
    "    for Folder in Anatomy_nifti['Path']:\r\n",
    "        Subject = Folder.split('/')[-2]\r\n",
    "        try: os.mkdir(directory + '/T1_backup/' + Subject)\r\n",
    "        except: pass\r\n",
    "        shutil.copy(glob(Folder+'/*.nii')[0], directory + '/T1_backup/' + Subject)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Script #3 Presets`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "coregister = {\r\n",
    "    'Objective_Function' : 'nmi',   #nmi: Normalized Mutual Information\r\n",
    "    'Separation'         : '[4 2]', #The average distance between sampled points (in mm)\r\n",
    "    'Tolerance'          : '[0.02 0.02 0.02 0.001 0.001 0.001 0.01 0.01 0.01 0.001 0.001 0.001]',      \r\n",
    "                                    #Iterations stop when differences between successive estimates are less thean the required tolerance\r\n",
    "    'Smoothing'          : '[7 7]'  #Gaussian smoothing to apply to the 256x256 joint histogram.\r\n",
    "}\r\n",
    "\r\n",
    "Segment = {\r\n",
    "    'Bias_regularization'     : 0.001,   #0 / 0.00001 / 0.0001 / 0.01 / 0.1 / 1 / 10 ==> ex) If bias is very little, set lower value\r\n",
    "    'Bias_FWHM'               : 60,      #mm, 30 / 40 / 50 / 60 / 70 / 80 / 90 / 100 / 110 / 120 / 130 / 140 / 150 / None\r\n",
    "    'Save_corrected_and_field': '[0 1]', #[Field, corrected]\r\n",
    "    'Num_gaussians'           : [1,1,2,3,4,2], #0~8, \r\n",
    "                                         #Used to represent the intensity distribution for each tissue class can be greater than one\r\n",
    "    'Native_Tissue'           : [ '[1 1]', '[1 1]', '[1 1]', '[1 0]', '[1 0]', '[0 0]' ], #[Native, Dartel]\r\n",
    "                                         #Produce a tissue class image (C*) that is in alignment with the original.[Dartel toolbox(rc*)]\r\n",
    "    'Warped_Tissue'           : [ '[1 0]', '[1 0]', '[1 0]', '[1 0]', '[1 0]', '[1 0]' ], #[Modulated, Unmodulated]\r\n",
    "                                         #Produce spatially normalised versions of the tissue class. (mwc* and wc*)\r\n",
    "    'MRF_Filter'              : 1,       #Strength of MRF\r\n",
    "                                         #Cleanup procedure for tissue class images with few iterations of a simple Markov Random Field \r\n",
    "    'Clean_up'                : 1,       #0: Don't cleanup, 1: Light Clean, 2: Thorough clean\r\n",
    "    'Warping_regularization'  : '[0 0.001 0.5 0.05 0.2]', #Read SPM manual for detailed instruction\r\n",
    "                                         #Measure of similarity between images and measure of the roughness of the deformation\r\n",
    "    'Affine_Regularization'   : 'eastern', \r\n",
    "    #No Affine Registration: ''\r\n",
    "    #No regularisation: 'none'\r\n",
    "    #ICBM space template - East Asian Brains: 'eastern'\r\n",
    "    #ICBM space template - European: 'mni'\r\n",
    "    #Average sized template: 'subj'\r\n",
    "    'Smoothness'              : 0,         #Derive a fudge factor to account for correlations between neighbouring voxels \r\n",
    "    'Sampling_distance'       : 3,         #Encodes the approximate distance between smapled points when estimating the model parameters\r\n",
    "    'Deformation_Fields'      : '[0 1]' #[Inverse, Forward]\r\n",
    "                                    #Forward: spatially normalizing image to MNI / Inverse: spatailly normalizing GIFTI surface files\r\n",
    "}\r\n",
    "\r\n",
    "Normalize = {\r\n",
    "    'Bounding_box' : [-78, -112, -70, 78, 76, 85],\r\n",
    "    'Voxel_sizes'  : '[2 2 2]',\r\n",
    "    'Interpolation': 4,\r\n",
    "    'fname_prefix' : 'w',\r\n",
    "    }\r\n",
    "\r\n",
    "Smoothing = {\r\n",
    "    'FWHM'         : '[10 10 10]',\r\n",
    "    'Data_type'    : 0        , #0: Same dtype as original, 1: UINT8, 2: INT16, 3: INT32, 4: Float32, 5: Float64\r\n",
    "    'Implicit_mask': 0        , \r\n",
    "    'fname_prefix' : 'FINAL_' \r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def script3_writer(index, path1, path2, coregister, segment, normalize, smoothing, FILE):\r\n",
    "    global SPM_PATH\r\n",
    "    Mean_EPI = glob(path2 + '/mean*')[0]\r\n",
    "    anatomy  = glob(path1 + '/*')[0]\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.ref    = {'%s,1'};\\n\"%(index, Mean_EPI))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.source = {'%s,1'};\\n\"%(index, anatomy))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.other  = {''};\\n\"%(index))\r\n",
    "    ########################################################################################################################################\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.eoptions.cost_fun = '%s';\\n\"%(index, coregister['Objective_Function']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.eoptions.sep = %s;\\n\"%(index, coregister['Separation']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.eoptions.tol = %s;\\n\"%(index, coregister['Tolerance']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.coreg.estimate.eoptions.fwhm = %s;\\n\"%(index, coregister['Smoothing']))\r\n",
    "########################################################################################################################################\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.channel.vols(1) = cfg_dep('Coregister: Estimate: Coregistered Images', substruct('.','val', '{}',{%d}, '.','val', '{}',{1}, '.','val', '{}',{1}, '.','val', '{}',{1}), substruct('.','cfiles'));\\n\"%(index+1,index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.channel.biasreg = %s;\\n\"%(index+1, segment['Bias_regularization']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.channel.biasfwhm = %s;\\n\"%(index+1,segment['Bias_FWHM']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.channel.write = %s;\\n\"%(index+1,segment['Save_corrected_and_field']))\r\n",
    "    for idx in range(1,7):\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.tissue(%d).tpm = {'%stpm/TPM.nii,%d'};\\n\"%(index+1, idx, SPM_PATH, idx))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.tissue(%d).ngaus = %d;\\n\"%(index+1, idx, segment['Num_gaussians'][idx-1]))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.tissue(%d).native = %s;\\n\"%(index+1, idx, segment['Native_Tissue'][idx-1]))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.tissue(%d).warped = %s;\\n\"%(index+1, idx, segment['Warped_Tissue'][idx-1]))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.mrf = %s;\\n\"%(index+1, segment['MRF_Filter']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.cleanup =  %s;\\n\"%(index+1, segment['Clean_up']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.reg = %s;\\n\"%(index+1, segment['Warping_regularization']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.affreg = '%s';\\n\"%(index+1, segment['Affine_Regularization']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.fwhm = %s;\\n\"%(index+1, segment['Smoothness']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.samp = %s;\\n\"%(index+1, segment['Sampling_distance']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.write = %s;\\n\"%(index+1, segment['Deformation_Fields']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.vox = NaN;\\n\"%(index+1))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.preproc.warp.bb = [NaN NaN NaN\\n\"%(index+1))\r\n",
    "    FILE.write(\"                                              NaN NaN NaN];\\n\")\r\n",
    "########################################################################################################################################\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.subj.def(1) = cfg_dep('Segment: Forward Deformations', substruct('.','val', '{}',{%d}, '.','val', '{}',{1}, '.','val', '{}',{1}), substruct('.','fordef', '()',{':'}));\\n\"%(index+2,index+1))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.subj.resample = {\\n\"%(index+2))\r\n",
    "    for imgs in glob(path2 + '/ars*'): FILE.write(\"                                                            '\" + imgs + \",1'\\n\")\r\n",
    "    FILE.write(\"                                                            };\\n\")\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.woptions.bb = [ %d %d %d\\n\"%(index+2,   normalize['Bounding_box'][0],\r\n",
    "                                                                                                    normalize['Bounding_box'][1],\r\n",
    "                                                                                                    normalize['Bounding_box'][2]))\r\n",
    "    FILE.write(\"                                                            %d %d %d];\\n\"%(         normalize['Bounding_box'][-3],\r\n",
    "                                                                                                    normalize['Bounding_box'][-2],\r\n",
    "                                                                                                    normalize['Bounding_box'][-1]))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.woptions.vox = %s;\\n\"%(index+2, normalize['Voxel_sizes']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.woptions.interp = %d;\\n\"%(index+2, normalize['Interpolation']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.normalise.write.woptions.prefix = '%s';\\n\"%(index+2, normalize['fname_prefix']))\r\n",
    "########################################################################################################################################\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.smooth.data(1) = cfg_dep('Normalise: Write: Normalised Images (Subj 1)', substruct('.','val', '{}',{%d}, '.','val', '{}',{1}, '.','val', '{}',{1}, '.','val', '{}',{1}), substruct('()',{1}, '.','files'));\\n\"%(index+3,index+2))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.smooth.fwhm = %s;\\n\"%(index+3, smoothing['FWHM']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.smooth.dtype = %d;\\n\"%(index+3, smoothing['Data_type']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.smooth.im = %d;\\n\"%(index+3, smoothing['Implicit_mask']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.spatial.smooth.prefix = '%s';\\n\\n\"%(index+3, smoothing['fname_prefix']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script3 = create_script(script_path, 'script3.m')\r\n",
    "print('Writing script...')\r\n",
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(fMRI_list['Path'])*4, 4 ) ):\r\n",
    "    script3_writer(i+1, Anatomy_nifti['Path'][idx], fMRI_nifti['Path'][idx], coregister, Segment, Normalize, Smoothing, FILE=script3)\r\n",
    "    idx += 1\r\n",
    "\r\n",
    "script3.close()\r\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fMRI_nifti['Path'].loc[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #4 fMRI model specification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Script #4 presets`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Use_art = False #If the value is set true, art(ARtifact detection Tool) batch generator will be run."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Fixed_path = False\r\n",
    "SPM_MAT_list = []\r\n",
    "Specification = {\r\n",
    "    'SPM.mat_dir': 'D:/Workspace/TEST/Control/SPM_MAT' if Fixed_path else filedialog.askdirectory(title='Where to save SPM.mat files?', \r\n",
    "                                                                                            initialdir=os.getcwd()),\r\n",
    "    'Units_for_design'    : 'secs', #'secs'\r\n",
    "    'Interscan_interval'  : 3,  #TR\r\n",
    "    'Microtime_resolution': 16,\r\n",
    "    'Microtime_onset'     : 8,\r\n",
    "    'Session_total'       : 3,\r\n",
    "    'Session_info'        :[ \r\n",
    "            #Session name             (ex) If there are two sessions, [ 'Task', 'Fixation' ]\r\n",
    "            ['A', 'B', 'Fixation'], \r\n",
    "            #Oneset times per session (ex) If there are two sessions, [ [0, 84, 120, 156], [36, 72, 132, 144, 216] ]  \r\n",
    "            [  [0.75, 5.5,10.25,15,19.75,24.5,29.25,34,38.75,43.5,48.25,53,228.75,233.5,238.25,243,247.75,252.5,257.25,262,266.75,\r\n",
    "                271.5,276.25,281,342.75,347.5,352.25,357,361.75,366.5,371.25,376,380.75,385.5,390.25,395],\r\n",
    "               [57.75,62.5,67.25,72,76.75,81.5,86.25,91,95.75,100.5,105.25,110,171.75,176.5,181.25,186,190.75,195.5\r\n",
    "               ,200.25,205,209.75,214.5,219.25,224,399.75,404.5,409.25,414,418.75,423.5,428.25,433,437.75,442.5,447.25,452],\r\n",
    "               [114,285,456]            ],\r\n",
    "            #Duration                 (ex) If there are two sessions, [ 10, 5 ] \r\n",
    "               [3.5, 3.5, 57.0], \r\n",
    "\r\n",
    "            #[], #Time modulations, 0: None, 1~6: order of time modulation (ex) If there are two sessions, [0, 0] ==> Working on it :<\r\n",
    "            #[], #Parametric modulations   ==> Working on it :<\r\n",
    "            #[], #Orthogonalise modulations, 0: no, 1: yes, (ex) If there are two sessions, [1, 1]] ==> Working on it :<\r\n",
    "    ],\r\n",
    "    #'Multiple_conditions': '', Working on it :<\r\n",
    "    #'Regressors'\r\n",
    "    'Multiple_regressor'  : 'rp', #Type prefix of multiple regressor file\r\n",
    "    'High_Pass_filter'    : 128,\r\n",
    "    #'Canionical_HRF'      : '[0 0]', Working on it :<\r\n",
    "    #'Global_normalization': 'None', Working on it :<\r\n",
    "    'Masking_threshold'   : 0.8,\r\n",
    "    #'Explicit_mask'      : '', Working on it :<\r\n",
    "    #'Serial_correlations : 'AR(1)', Working on it :<\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(Specification['SPM.mat_dir'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def script4_writer(index, fMRI_path, specification, FILE, final_prefix='FINAL_'):\r\n",
    "    try: os.mkdir(specification['SPM.mat_dir']+'/'+ fMRI_path.split('/')[-2])\r\n",
    "    except: pass\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.dir = {'%s'};\\n\"%(index, specification['SPM.mat_dir']+'/'+ fMRI_path.split('/')[-2]))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.timing.units = '%s';\\n\"%(index, specification['Units_for_design']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.timing.RT = %d;\\n\"%(index, specification['Interscan_interval']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.timing.fmri_t = %d;\\n\"%(index, specification['Microtime_resolution']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.timing.fmri_t0 = %d;\\n\"%(index,specification['Microtime_onset']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.scans = {\\n\"%(index))\r\n",
    "    for imgs in glob(fMRI_path + '/' + final_prefix + '*.nii'):\r\n",
    "        FILE.write(\"                                                    '%s,1'\\n\"%(imgs))\r\n",
    "    FILE.write(\"                                                    };\\n\")\r\n",
    "    \r\n",
    "    for sess in range(specification['Session_total']):\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).name = '%s';\\n\"%(index, sess+1, specification['Session_info'][0][sess]))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).onset = [%d\\n\"%(index, sess+1,specification['Session_info'][1][sess][0]))\r\n",
    "        for i in range( 1, len( specification['Session_info'][1][sess] ) ):\r\n",
    "            FILE.write(\"                                                         %d\\n\"%(specification['Session_info'][1][sess][i]))\r\n",
    "        FILE.write(\"                                                         %d];\\n\"%(specification['Session_info'][1][sess][-1]))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).duration = %d;\\n\"%(index, sess+1, specification['Session_info'][2][sess]))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).tmod = 0;\\n\"%(index, sess+1))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).pmod = struct('name', {}, 'param', {}, 'poly', {});\\n\"%(index, sess+1))\r\n",
    "        FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.cond(%d).orth = 1;\\n\\n\"%(index, sess+1))\r\n",
    "\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.multi = {''};\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.regress = struct('name', {}, 'val', {});\\n\"%(index))\r\n",
    "    print(glob(fMRI_path+'/'+specification['Multiple_regressor']+'*')[0])\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.multi_reg = {'%s'};\\n\"%(index,glob(fMRI_path+'/'+specification['Multiple_regressor']+'*')[0]))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.sess.hpf = %s;\\n\"%(index, specification['High_Pass_filter']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.fact = struct('name', {}, 'levels', {});\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.bases.hrf.derivs = [0 0];\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.volt = 1;\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.global = 'None';\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.mthresh = %s;\\n\"%(index,  specification['Masking_threshold']))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.mask = {''};\\n\"%(index))\r\n",
    "    FILE.write(\"matlabbatch{%d}.spm.stats.fmri_spec.cvi = 'AR(1)';\\n\"%(index))\r\n",
    "\r\n",
    "    return specification['SPM.mat_dir']+'/'+ fMRI_path.split('/')[-2] + '/SPM.mat'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script4 = create_script(script_path, 'script4.m')\r\n",
    "print('Writing script...')\r\n",
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(fMRI_list['Path']) ) ):\r\n",
    "    rtn = script4_writer(i+1, fMRI_nifti['Path'][idx], Specification, FILE=script4)\r\n",
    "    SPM_MAT_list.append( rtn )\r\n",
    "    idx += 1\r\n",
    "\r\n",
    "script4.close()\r\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #5 Model estimation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def script5_writer(index, SPM_MAT_path, FILE):\r\n",
    "   FILE.write(\"matlabbatch{%d}.spm.stats.fmri_est.spmmat = {'%s'};\\n\"%(index, SPM_MAT_path))\r\n",
    "   FILE.write(\"matlabbatch{%d}.spm.stats.fmri_est.write_residuals = 0;\\n\"%(index) )\r\n",
    "   FILE.write(\"matlabbatch{%d}.spm.stats.fmri_est.method.Classical = 1;\\n\"%(index) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "script5 = create_script(script_path, 'script5.m')\r\n",
    "print('Writing script...')\r\n",
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(SPM_MAT_list) ) ):\r\n",
    "    #if 'KJH' not in SPM_MAT_list[i]:\r\n",
    "    script5_writer(idx+1, SPM_MAT_list[i], FILE=script5)\r\n",
    "    idx += 1\r\n",
    "\r\n",
    "script5.close()\r\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Script #6 Contrast Manager"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(Specification['Session_info'][0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Contrast = {\r\n",
    "    'A-B'   : '[-1 1 0]',\r\n",
    "    'A-Fix' : '[0 1 -1]',\r\n",
    "    'B-Fix' : '[1 0 -1]',\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try: os.mkdir(script_path+'/contrast_script')\r\n",
    "except: pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_script_for6(path, idx):\r\n",
    "    runner = open(path + '/run_job_' + '{}.m'.format(idx), 'w')\r\n",
    "    runner.write(\"\"\"%% List of open inputs\r\n",
    "nrun = 1; %% enter the number of runs here\r\n",
    "jobfile = {'%s'};\r\n",
    "jobs = repmat(jobfile, 1, nrun);\r\n",
    "inputs = cell(0, nrun);\r\n",
    "for crun = 1:nrun\r\n",
    "end\r\n",
    "spm('defaults', 'FMRI');\r\n",
    "spm_jobman('run', jobs, inputs{:});\r\n",
    "\"\"\"%(path + '/job_{}.m'.format(idx) ))\r\n",
    "\r\n",
    "def script6_writer(index, SPM_MAT_path, contrast, path):\r\n",
    "    with open(path+'/job_{}.m'.format(index),'w') as FILE:\r\n",
    "        FILE.write(\"matlabbatch{1}.spm.stats.con.spmmat = {'%s'};\\n\"%(SPM_MAT_path))\r\n",
    "        for Name, seq in zip(contrast, range(1,len(contrast)+1)):\r\n",
    "            FILE.write(\"matlabbatch{1}.spm.stats.con.consess{%d}.tcon.name = '%s';\\n\"%(seq,Name) )\r\n",
    "            FILE.write(\"matlabbatch{1}.spm.stats.con.consess{%d}.tcon.weights = %s;\\n\"%(seq,contrast[Name]) )\r\n",
    "            FILE.write(\"matlabbatch{1}.spm.stats.con.consess{%d}.tcon.sessrep = 'none';\\n\"%(seq) )\r\n",
    "        FILE.write(\"matlabbatch{1}.spm.stats.con.delete = 1;\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idx = 0\r\n",
    "for i in tqdm(range(0, len(SPM_MAT_list))):\r\n",
    "    #if 'KJH' not in SPM_MAT_list[i]:\r\n",
    "    create_script_for6(script_path+'/contrast_script', idx)\r\n",
    "    script6_writer(idx, SPM_MAT_list[i], Contrast, script_path+'/contrast_script')\r\n",
    "    idx += 1\r\n",
    "print('Done!')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}